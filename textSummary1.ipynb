{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7ec23eb80a8a458483f47a63da3f396b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_35049340fcee4f4fb3408789b614d5a6",
              "IPY_MODEL_3ed933e6f10d460081c2d35ea9a6bd0f",
              "IPY_MODEL_c3df9ba651ef4669888ba112081ea5b9"
            ],
            "layout": "IPY_MODEL_1bb256e56c06450fb7efc23d2f5ed801"
          }
        },
        "35049340fcee4f4fb3408789b614d5a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34a761de6109476a908e88851706fa63",
            "placeholder": "​",
            "style": "IPY_MODEL_44f031866b58444eb1a399caa48e440d",
            "value": "100%"
          }
        },
        "3ed933e6f10d460081c2d35ea9a6bd0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_775c0d1b0d854a91a956747de63992c0",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_00947543fc934b4d83d537de0b34de17",
            "value": 3
          }
        },
        "c3df9ba651ef4669888ba112081ea5b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4f3a07afa7e4cdbb57ebc10364cff70",
            "placeholder": "​",
            "style": "IPY_MODEL_252ad68ce6bd4332950271ce1876cae9",
            "value": " 3/3 [00:00&lt;00:00,  3.83it/s]"
          }
        },
        "1bb256e56c06450fb7efc23d2f5ed801": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34a761de6109476a908e88851706fa63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44f031866b58444eb1a399caa48e440d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "775c0d1b0d854a91a956747de63992c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00947543fc934b4d83d537de0b34de17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e4f3a07afa7e4cdbb57ebc10364cff70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "252ad68ce6bd4332950271ce1876cae9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2hKxrrXiiL3",
        "outputId": "6e47293f-2827-43eb-b1b3-ddd709257171"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.3.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Upgrade pip\n",
        "%pip install --upgrade pip\n",
        "\n",
        "# Install torch and torchdata with specified versions\n",
        "%pip install --disable-pip-version-check torch==1.13.1 torchdata==0.5.1 --quiet\n",
        "\n",
        "# Install transformers and datasets\n",
        "%pip install transformers==4.27.2 datasets==2.11.0 --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer"
      ],
      "metadata": {
        "id": "W9qEI3ZelB4k"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "huggingface_dataset_name = \"knkarthick/dialogsum\"\n",
        "\n",
        "# Load the dataset\n",
        "dataset = load_dataset(huggingface_dataset_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "7ec23eb80a8a458483f47a63da3f396b",
            "35049340fcee4f4fb3408789b614d5a6",
            "3ed933e6f10d460081c2d35ea9a6bd0f",
            "c3df9ba651ef4669888ba112081ea5b9",
            "1bb256e56c06450fb7efc23d2f5ed801",
            "34a761de6109476a908e88851706fa63",
            "44f031866b58444eb1a399caa48e440d",
            "775c0d1b0d854a91a956747de63992c0",
            "00947543fc934b4d83d537de0b34de17",
            "e4f3a07afa7e4cdbb57ebc10364cff70",
            "252ad68ce6bd4332950271ce1876cae9"
          ]
        },
        "id": "3dfmFKeClIZS",
        "outputId": "181e1af4-a511-4815-bca8-f6a45ef021a4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset csv (/root/.cache/huggingface/datasets/knkarthick___csv/knkarthick--dialogsum-cd36827d3490488d/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ec23eb80a8a458483f47a63da3f396b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_example(index, dash_length=80):\n",
        "    dash_line = '-' * dash_length\n",
        "\n",
        "    print(dash_line)\n",
        "    print(f'Example {index + 1}')\n",
        "    print(dash_line)\n",
        "\n",
        "\n",
        "    input_dialogue = dataset['test'][index]['dialogue']\n",
        "    baseline_summary = dataset['test'][index]['summary']\n",
        "\n",
        "    print('INPUT DIALOGUE:')\n",
        "    print(input_dialogue)\n",
        "    print(dash_line)\n",
        "    print('BASELINE HUMAN SUMMARY:')\n",
        "    print(baseline_summary)\n",
        "    print(dash_line)\n",
        "    print()\n",
        "\n",
        "\n",
        "\n",
        "example_indices = [30, 150]\n",
        "custom_dash_length = 120\n",
        "\n",
        "for i, index in enumerate(example_indices):\n",
        "    print_example(index, custom_dash_length)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L86sx45llLqm",
        "outputId": "867571c2-f551-490b-8f36-f7ef1790894a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------------------------------------------------------\n",
            "Example 31\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "INPUT DIALOGUE:\n",
            "#Person1#: Where are you going for your trip?\n",
            "#Person2#: I think Hebei is a good place.\n",
            "#Person1#: But I heard the north of China are experiencing severe sandstorms!\n",
            "#Person2#: Really?\n",
            "#Person1#: Yes, it's said that Hebes was experiencing six degree strong winds.\n",
            "#Person2#: How do these storms affect the people who live in these areas?\n",
            "#Person1#: The report said the number of people with respiratory tract infections tended to rise after sandstorms. The sand gets into people's noses and throats and creates irritation.\n",
            "#Person2#: It sounds that sandstorms are trouble for everybody!\n",
            "#Person1#: You are quite right.\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "BASELINE HUMAN SUMMARY:\n",
            "#Person2# plans to have a trip in Hebei but #Person1# says there are sandstorms in there.\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "Example 151\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "INPUT DIALOGUE:\n",
            "#Person1#: Taxi!\n",
            "#Person2#: Where will you go, sir?\n",
            "#Person1#: Friendship Hotel.\n",
            "#Person2#: OK, it's not far from here.\n",
            "#Person1#: I have something important to do, can you fast the speed?\n",
            "#Person2#: Sure, I'll try my best. Here we are.\n",
            "#Person1#: It's fast! How much should I pay you?\n",
            "#Person2#: The reading on the meter is 15 yuan.\n",
            "#Person1#: Here's 20 yuan, keep the change.\n",
            "#Person2#: Thank you very much.\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "BASELINE HUMAN SUMMARY:\n",
            "#Person1# takes a taxi to the Friendship Hotel for something important.\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'google/flan-t5-base'\n",
        "\n",
        "#Load pre-trained model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "uH7ky9julQ7l"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_decode_sentence(sentence, tokenizer):\n",
        "    # Encode the sentence\n",
        "    sentence_encoded = tokenizer(sentence, return_tensors='pt')\n",
        "\n",
        "    # Decode the encoded sentence\n",
        "    sentence_decoded = tokenizer.decode(\n",
        "        sentence_encoded[\"input_ids\"][0],\n",
        "        skip_special_tokens=True\n",
        "    )\n",
        "\n",
        "    return sentence_encoded, sentence_decoded\n",
        "\n",
        "# Change sentence value\n",
        "new_sentence = \"How are you doing today?\"\n",
        "tokenizer = AutoTokenizer.from_pretrained('google/flan-t5-base')\n",
        "\n",
        "sentence_encoded, sentence_decoded = encode_decode_sentence(new_sentence, tokenizer)\n",
        "\n",
        "print('ENCODED SENTENCE:')\n",
        "print(sentence_encoded[\"input_ids\"][0])\n",
        "print('\\nDECODED SENTENCE:')\n",
        "print(sentence_decoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8HIZdJPlcYk",
        "outputId": "675a7094-3ece-4bb3-a5d3-8eca38e18f01"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ENCODED SENTENCE:\n",
            "tensor([571,  33,  25, 692, 469,  58,   1])\n",
            "\n",
            "DECODED SENTENCE:\n",
            "How are you doing today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "def generate_summary(dialogue, model, tokenizer, max_tokens=50):\n",
        "    prompt = f\"\"\"\n",
        "Summarize the following conversation.\n",
        "\n",
        "{dialogue}\n",
        "\n",
        "Summary:\n",
        "\"\"\"\n",
        "\n",
        "    # Input constructed prompt instead of the dialogue.\n",
        "    inputs = tokenizer(prompt, return_tensors='pt')\n",
        "    output = tokenizer.decode(\n",
        "        model.generate(\n",
        "            inputs[\"input_ids\"],\n",
        "            max_new_tokens=max_tokens,\n",
        "        )[0],\n",
        "        skip_special_tokens=True\n",
        "    )\n",
        "\n",
        "    return output\n",
        "\n",
        "example_indices = [30, 150]\n",
        "tokenizer = AutoTokenizer.from_pretrained('google/flan-t5-base')\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained('google/flan-t5-base')\n",
        "\n",
        "for i, index in enumerate(example_indices):\n",
        "    dialogue = dataset['test'][index]['dialogue']\n",
        "    summary = dataset['test'][index]['summary']\n",
        "\n",
        "    generated_summary = generate_summary(dialogue, model, tokenizer)\n",
        "\n",
        "    # Print or store the generated summary for analysis\n",
        "    print(f'MODEL GENERATION - ZERO SHOT:\\n{generated_summary}\\n')\n",
        "\n",
        "    dash_line = '-' * 80\n",
        "    print(dash_line)\n",
        "    print(f'Example {i + 1}')\n",
        "    print(dash_line)\n",
        "    print(f'INPUT DIALOGUE:\\n{dialogue}')\n",
        "    print(dash_line)\n",
        "    print(f'BASELINE HUMAN SUMMARY:\\n{summary}')\n",
        "    print(dash_line)\n",
        "    print(f'MODEL GENERATION - ZERO SHOT:\\n{generated_summary}\\n')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyEt6oZzllwe",
        "outputId": "0e4f3d2a-6d6f-4b37-cfd0-92b301112bca"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MODEL GENERATION - ZERO SHOT:\n",
            "The sandstorms in China are causing a lot of health problems for people in the north of China.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Example 1\n",
            "--------------------------------------------------------------------------------\n",
            "INPUT DIALOGUE:\n",
            "#Person1#: Where are you going for your trip?\n",
            "#Person2#: I think Hebei is a good place.\n",
            "#Person1#: But I heard the north of China are experiencing severe sandstorms!\n",
            "#Person2#: Really?\n",
            "#Person1#: Yes, it's said that Hebes was experiencing six degree strong winds.\n",
            "#Person2#: How do these storms affect the people who live in these areas?\n",
            "#Person1#: The report said the number of people with respiratory tract infections tended to rise after sandstorms. The sand gets into people's noses and throats and creates irritation.\n",
            "#Person2#: It sounds that sandstorms are trouble for everybody!\n",
            "#Person1#: You are quite right.\n",
            "--------------------------------------------------------------------------------\n",
            "BASELINE HUMAN SUMMARY:\n",
            "#Person2# plans to have a trip in Hebei but #Person1# says there are sandstorms in there.\n",
            "--------------------------------------------------------------------------------\n",
            "MODEL GENERATION - ZERO SHOT:\n",
            "The sandstorms in China are causing a lot of health problems for people in the north of China.\n",
            "\n",
            "MODEL GENERATION - ZERO SHOT:\n",
            "The taxi will pick up Person1 at Friendship Hotel.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Example 2\n",
            "--------------------------------------------------------------------------------\n",
            "INPUT DIALOGUE:\n",
            "#Person1#: Taxi!\n",
            "#Person2#: Where will you go, sir?\n",
            "#Person1#: Friendship Hotel.\n",
            "#Person2#: OK, it's not far from here.\n",
            "#Person1#: I have something important to do, can you fast the speed?\n",
            "#Person2#: Sure, I'll try my best. Here we are.\n",
            "#Person1#: It's fast! How much should I pay you?\n",
            "#Person2#: The reading on the meter is 15 yuan.\n",
            "#Person1#: Here's 20 yuan, keep the change.\n",
            "#Person2#: Thank you very much.\n",
            "--------------------------------------------------------------------------------\n",
            "BASELINE HUMAN SUMMARY:\n",
            "#Person1# takes a taxi to the Friendship Hotel for something important.\n",
            "--------------------------------------------------------------------------------\n",
            "MODEL GENERATION - ZERO SHOT:\n",
            "The taxi will pick up Person1 at Friendship Hotel.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary"
      ],
      "metadata": {
        "id": "PbQS5nuRlYTR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_prompt(example_indices_full, example_index_to_summarize):\n",
        "    prompt = ''\n",
        "    for index in example_indices_full:\n",
        "        dialogue = dataset['test'][index]['dialogue']\n",
        "        summary = dataset['test'][index]['summary']\n",
        "\n",
        "        # The stop sequence '{summary}\\n\\n\\n' is important for FLAN-T5. Other models may have their own preferred stop sequence.\n",
        "        prompt += f\"\"\"\n",
        "Dialogue:\n",
        "\n",
        "{dialogue}\n",
        "\n",
        "What was going on?\n",
        "{summary}\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    dialogue = dataset['test'][example_index_to_summarize]['dialogue']\n",
        "\n",
        "    prompt += f\"\"\"\n",
        "Dialogue:\n",
        "\n",
        "{dialogue}\n",
        "\n",
        "What was going on?\n",
        "\"\"\"\n",
        "\n",
        "    return prompt"
      ],
      "metadata": {
        "id": "Pop7KCOy9ZQ4"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_indices_full = [10, 50, 90]\n",
        "example_index_to_summarize = 160\n",
        "\n",
        "few_shot_prompt = make_prompt(example_indices_full, example_index_to_summarize)\n",
        "\n",
        "print(few_shot_prompt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rP5DtsiZ9Skd",
        "outputId": "79692c5f-dbbe-4b19-f6ce-3378452187b4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dialogue:\n",
            "\n",
            "#Person1#: Happy Birthday, this is for you, Brian.\n",
            "#Person2#: I'm so happy you remember, please come in and enjoy the party. Everyone's here, I'm sure you have a good time.\n",
            "#Person1#: Brian, may I have a pleasure to have a dance with you?\n",
            "#Person2#: Ok.\n",
            "#Person1#: This is really wonderful party.\n",
            "#Person2#: Yes, you are always popular with everyone. and you look very pretty today.\n",
            "#Person1#: Thanks, that's very kind of you to say. I hope my necklace goes with my dress, and they both make me look good I feel.\n",
            "#Person2#: You look great, you are absolutely glowing.\n",
            "#Person1#: Thanks, this is a fine party. We should have a drink together to celebrate your birthday\n",
            "\n",
            "What was going on?\n",
            "#Person1# attends Brian's birthday party. Brian thinks #Person1# looks great and charming.\n",
            "\n",
            "\n",
            "\n",
            "Dialogue:\n",
            "\n",
            "#Person1#: Yeah. Just pull on this strip. Then peel off the back.\n",
            "#Person2#: You might make a few enemies this way.\n",
            "#Person1#: If they don't think this is fun, they're not meant to be our friends.\n",
            "#Person2#: You mean your friends. I think it's cruel.\n",
            "#Person1#: Yeah. But it's fun. Look at those two ugly old ladies. . . or are they men?\n",
            "#Person2#: Hurry! Get a shot!. . . Hand it over!\n",
            "#Person1#: I knew you'd come around. . .\n",
            "\n",
            "What was going on?\n",
            "#Person1# is about to make a prank. #Person2# thinks it's cruel at first but then joins.\n",
            "\n",
            "\n",
            "\n",
            "Dialogue:\n",
            "\n",
            "#Person1#: What's wrong with you, Mr. Polly?\n",
            "#Person2#: What's wrong? I want a break from this horrible job.\n",
            "#Person1#: Then, buy a bottle of soft drink.\n",
            "#Person2#: Would you like to buy a bottle for me in the shop?\n",
            "#Person1#: It's a problem, because my boss is in that shop now.\n",
            "#Person2#: Ok, I will go there myself.\n",
            "#Person1#: Sorry, Mr. Polly.\n",
            "#Person2#: It doesn't matter. Oh, God, I have only four dollars in my wallet. Is that possible for me to buy one?\n",
            "#Person1#: Have a try.\n",
            "\n",
            "What was going on?\n",
            "Mr. Polly is tired and wants a break from work. #Person1# cannot buy a bottle of soft drink for him.\n",
            "\n",
            "\n",
            "\n",
            "Dialogue:\n",
            "\n",
            "#Person1#: Did you hear about Lulu?\n",
            "#Person2#: No, what?\n",
            "#Person1#: She and Vic broke up and now she ' s asked for a transfer.\n",
            "#Person2#: Get out of here! I didn ' t even know they were dating!\n",
            "#Person1#: No one really did. They were very discreet and professional at the office.\n",
            "\n",
            "What was going on?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary = dataset['test'][example_index_to_summarize]['summary']\n",
        "\n",
        "inputs = tokenizer(few_shot_prompt, return_tensors='pt')\n",
        "output = tokenizer.decode(\n",
        "    model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        max_new_tokens=50,\n",
        "    )[0],\n",
        "    skip_special_tokens=True\n",
        ")\n",
        "\n",
        "print(dash_line)\n",
        "print(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\n",
        "print(dash_line)\n",
        "print(f'MODEL GENERATION - FEW SHOT:\\n{output}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDpVno3u_5bV",
        "outputId": "2382b155-d832-4dcb-b10d-ce4942036d8c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "BASELINE HUMAN SUMMARY:\n",
            "#Person1# and #Person2# are talking about Lulu and Vic's breakup.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "MODEL GENERATION - FEW SHOT:\n",
            "Lulu and Vic broke up and now they are dating.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GenerationConfig\n",
        "generation_config = GenerationConfig(max_new_tokens=50)\n",
        "# generation_config = GenerationConfig(max_new_tokens=10)\n",
        "# generation_config = GenerationConfig(max_new_tokens=50, do_sample=True, temperature=0.1)\n",
        "# generation_config = GenerationConfig(max_new_tokens=50, do_sample=True, temperature=0.5)\n",
        "# generation_config = GenerationConfig(max_new_tokens=50, do_sample=True, temperature=1.0)\n",
        "\n",
        "inputs = tokenizer(few_shot_prompt, return_tensors='pt')\n",
        "output = tokenizer.decode(\n",
        "    model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        generation_config=generation_config,\n",
        "    )[0],\n",
        "    skip_special_tokens=True\n",
        ")\n",
        "\n",
        "print(dash_line)\n",
        "print(f'MODEL GENERATION - FEW SHOT:\\n{output}')\n",
        "print(dash_line)\n",
        "print(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsZDIYg-9BmD",
        "outputId": "3d658e95-ad81-4441-c51a-7c2aecadaafc"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "MODEL GENERATION - FEW SHOT:\n",
            "Lulu and Vic broke up and now they are dating.\n",
            "--------------------------------------------------------------------------------\n",
            "BASELINE HUMAN SUMMARY:\n",
            "#Person1# and #Person2# are talking about Lulu and Vic's breakup.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rJXR6bXQlIGs"
      }
    }
  ]
}
